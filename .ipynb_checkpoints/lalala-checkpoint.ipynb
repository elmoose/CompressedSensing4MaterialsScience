{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"teaser\" style=' background-position:  right center; background-size: 00px; background-repeat: no-repeat; \n",
    "    padding-top: 20px;\n",
    "    padding-right: 10px;\n",
    "    padding-bottom: 170px;\n",
    "    padding-left: 10px;\n",
    "    border-bottom: 14px double #333;\n",
    "    border-top: 14px double #333;' > \n",
    "\n",
    "   \n",
    "   <div style=\"text-align:center\">\n",
    "    <b><font size=\"6.4\">Compressed sensing for identifying materials descriptors</font></b>    \n",
    "  </div>\n",
    "    \n",
    "<p>\n",
    " created by:\n",
    " Emre Ahmetcik<sup>1</sup>, \n",
    " Angelo Ziletti<sup>1</sup>,\n",
    " Runhai Ouyang<sup> 1</sup>,\n",
    " Luca Ghiringhelli<sup> 1</sup>,\n",
    " and Matthias Scheffler<sup>1</sup> <br><br>\n",
    "   \n",
    "<sup>1</sup> Fritz Haber Institute of the Max Planck Society, Faradayweg 4-6, D-14195 Berlin, Germany <br>\n",
    "<span class=\"nomad--last-updated\" data-version=\"v1.0.0\">[Last updated: April 5, 2019]</span>\n",
    "</p>\n",
    "\n",
    "      \n",
    "<div> \n",
    "<img  style=\"float: left;\" src=\"data/Logo_MPG.png\" width=\"200\"> \n",
    "<img  style=\"float: right;\" src=\"data/Logo_NOMAD.png\" width=\"250\">\n",
    "</div>\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to find descriptive parameters (short formulas) to predict materials properties using compressed sensing tools. As an example, we address the prediction of the zincblende (ZB) versus rocksalt (RS) relative stability of 82 octet binary materials.\n",
    "\n",
    "The idea of using compressed sensing tools: Starting from simple physical quantities (\"building blocks\", here properties of the constituent free atoms such as orbital radii), millions (or billions) of candidate formulas are generated by applying arithmetic operations combining building blocks, for example forming sums and products of them. These candidate formulas constitute the so-called \"feature space\". Then a compressed sensing based method is used to select only a few of these formulas that explain the data, as described in \n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "L. M. Ghiringhelli, J. Vybiral, S. V. Levchenko, C. Draxl, M. Scheffler: <span style=\"font-style: italic;\">Big Data of Materials Science: Critical Role of the Descriptor</span>,  Phys. Rev. Lett. 114, 105503 (2015) <a href=\"http://journals.aps.org/prl/abstract/10.1103/PhysRevLett.114.105503\" target=\"_blank\">[PDF]</a>.</div>\n",
    "In this tutorial we use the Sure Independence Screening and Sparsifying  Operator  (SISSO) as introduced in\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "R. Ouyang, S. Curtarolo, E. Ahmetcik, M. Scheffler, L. M. Ghiringhelli: <span style=\"font-style: italic;\">SISSO: a compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates</span>, Phys. Rev. Materials  2, 083802 (2018) <a href=\"https://journals.aps.org/prmaterials/abstract/10.1103/PhysRevMaterials.2.083802\" target=\"_blank\">[PDF]</a> .\n",
    "</div>\n",
    "\n",
    "# Introduction to the compressed sensing methods\n",
    "\n",
    "The feature space is generated by creating a list of analytical expressions (the derived features), obtained by combining <i> primary features </i> and arithmetic operations. In this example, the primary features are properties of isolated atoms, such as electorn affinity or the radial extension of valence orbitals. We put all $m$ derived features into a descriptor matrix $\\mathbf{D} \\in \\mathbb{R}^{82 \\times m}$ where each column stands for a derived feature and each row for a compound. An $\\ell_0$-regularization \n",
    "\n",
    "$\\text{argmin}_{\\mathbf{c} \\in \\mathbb{R}^{m}} \\{\\|\\mathbf{P} - \\mathbf{D}\\mathbf{c}\\|^2_2 +\\lambda \\|\\mathbf{c}\\|_0\\}$\n",
    "\n",
    "determines those few feature columns which approximate a property vector $\\mathbf{P} \\in \\mathbb{R}^{82}$ (i.e RS vs. ZB energy differences) best. The subscript 0 stands for the $\\ell_0$-quasinorm, that counts the number of non-zero elements of $\\mathbf{c}$ and $\\lambda > 0$ is called the regularization parameter. Performing the $\\ell_0$-regularization becomes fast computational infeasable and often approximations (i.e. LASSO, orthogonal matching pursuit) are needed since in practice the $\\ell_0$-regularization needs to be solved combinatorial: All singletons, pairs, triplets, ... $n$-tuples (up to the selected maximum dimension of the descriptor) are listed and for each set a least-square regression is performed. The $n$-tuple that gives the lowest mean square error for the least-square regression fit is selected as the resulting $n$-dimensional descriptor.\n",
    "\n",
    "### The LASSO method\n",
    "A convex optimization problem can be introduced by the Least Absolute Shrinkage and Selection Operator (LASSO):\n",
    "\n",
    "$\\text{argmin}_{\\mathbf{c} \\in \\mathbb{R}^{m}} \\{\\|\\mathbf{P} - \\mathbf{D}\\mathbf{c}\\|^2_2 +\\lambda \\|\\mathbf{c}\\|_1\\}$.\n",
    "\n",
    "Under certain conditions on the matrix $\\mathbf{D}$, it can find the exact solution of, or a good approximation to, the $\\ell_0$-regularization problem.\n",
    "\n",
    "\n",
    "### The SISSO method\n",
    "SISSO works iteratively. In the first iteration, a number $k$ of features is collected that have the largest correlation (scalar product) with $\\mathbf{P}$. The feature with the largest correlation is simply the 1D descriptor. Next, a residual is constructed as the error made in the first iteration. A new set of $k$ features is now selected as those having the largest correlation with the residual. The 2D descriptor is the pair of features that yield the smallest fitting error upon least-square regression, among all possible pairs contained in the union of the sets selected in this and the first iteration. In each next iteration a new residual is constructed as the error made in the previous iteration, then a new set of $k$ features is extracted as those that have largest correlation with each new residual. The $n$D descriptor is the $n$-tuple of features that yield the smallest fitting error upon least square regression, among all possible $n$-tuples contained in the union of the sets obtained in each new iteration and all the previous iterations. If $k=1$ the method collapses to the so-called orthogonal matching pursuit.\n",
    "<img  src=\"data/SISSO.png\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import Lasso\n",
    "import scipy.stats as ss\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "\n",
    "from modules.load_data import load_data\n",
    "from modules.sisso import SissoRegressor\n",
    "#from modules.combine_features import combine_features\n",
    "from modules.viewer import show_structure, show_map, show_scatter_plot\n",
    "\n",
    "# set display options for the notebook \n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to notebook directory, this is needed to run the tutorial\n",
    "os.chdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "Let us load the data from the file data/data.pkl into a data frame. The data was downloaded from the NOMAD archive and the NOMAD atomic data collection. It consists of RS-ZB energy differences (in eV/atom) of the 82 octet binary compounds, structure objects containing the atomic positions of the materials and properties of the atomic constituents. The following atomic features are considered:\n",
    "\n",
    "<div >\n",
    "   <ul>\n",
    "      <li>Z:  atomic number</li>\n",
    "      <li>period: period in the periodic table</li>\n",
    "      <li>IP: ionization potential</li>\n",
    "      <li>EA: electron affinity</li>      \n",
    "      <li>E_HOMO: energy of the highest occupied atomic orbital</li>\n",
    "      <li>E_LUMO: energy of the lowest unoccupied atomic orbital</li>   \n",
    "      <li>r_(s, p, d): radius where the radial distribution of s, p or d orbital has its maximum.</li>\n",
    "   </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Ru</th>\n",
       "      <th>Rh</th>\n",
       "      <th>Ir</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Pd</th>\n",
       "      <th>IWI</th>\n",
       "      <th>WI</th>\n",
       "      <th>CI</th>\n",
       "      <th>SI</th>\n",
       "      <th>SGP</th>\n",
       "      <th>CP</th>\n",
       "      <th>HDP</th>\n",
       "      <th>UGC</th>\n",
       "      <th>SCT</th>\n",
       "      <th>FSP</th>\n",
       "      <th>ME</th>\n",
       "      <th>DP</th>\n",
       "      <th>Calc T (oC)</th>\n",
       "      <th>Calc T. (hr)</th>\n",
       "      <th>Al2O3</th>\n",
       "      <th>MgO</th>\n",
       "      <th>CeO2</th>\n",
       "      <th>TiO2</th>\n",
       "      <th>ZEO</th>\n",
       "      <th>MnO</th>\n",
       "      <th>Y2O3</th>\n",
       "      <th>ZrO2</th>\n",
       "      <th>HAP</th>\n",
       "      <th>ACC</th>\n",
       "      <th>Tb4O7</th>\n",
       "      <th>HfO2</th>\n",
       "      <th>La2O3</th>\n",
       "      <th>Co3O4</th>\n",
       "      <th>ThO2</th>\n",
       "      <th>SiO2</th>\n",
       "      <th>Fe2O3</th>\n",
       "      <th>Sm2O3</th>\n",
       "      <th>Gd2O3</th>\n",
       "      <th>Yb2O3</th>\n",
       "      <th>CaO</th>\n",
       "      <th>YSZ</th>\n",
       "      <th>Li</th>\n",
       "      <th>Ce</th>\n",
       "      <th>Co</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Mn</th>\n",
       "      <th>Zr</th>\n",
       "      <th>K</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Cs</th>\n",
       "      <th>V</th>\n",
       "      <th>Rb</th>\n",
       "      <th>Y</th>\n",
       "      <th>Na</th>\n",
       "      <th>La</th>\n",
       "      <th>Gd</th>\n",
       "      <th>Yb</th>\n",
       "      <th>Zn</th>\n",
       "      <th>Re</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Ho</th>\n",
       "      <th>Nd</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Sm</th>\n",
       "      <th>Er</th>\n",
       "      <th>Sr</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>H2 vol.%</th>\n",
       "      <th>O2 vol.%</th>\n",
       "      <th>CO vol.%</th>\n",
       "      <th>H2O vol.%</th>\n",
       "      <th>CO2 vol.%</th>\n",
       "      <th>CH4 vol.%</th>\n",
       "      <th>TOS (min)</th>\n",
       "      <th>F/W (mg.min/ml)</th>\n",
       "      <th>Metal_Radius_Kittel</th>\n",
       "      <th>Metal_EN_Allen</th>\n",
       "      <th>Metal_Atomic_Num</th>\n",
       "      <th>Metal_T_melt</th>\n",
       "      <th>Metal_VE_Villars</th>\n",
       "      <th>Metal_Atomic_Wt</th>\n",
       "      <th>Metal_Group</th>\n",
       "      <th>Metal_Period</th>\n",
       "      <th>Metal_Density</th>\n",
       "      <th>Metal_T_boiling</th>\n",
       "      <th>Promo_Radius_Kittel</th>\n",
       "      <th>Promo_EN_Allen</th>\n",
       "      <th>Promo_Atomic_Num</th>\n",
       "      <th>Promo_T_melt</th>\n",
       "      <th>Promo_VE_Villars</th>\n",
       "      <th>Promo_Atomic_Wt</th>\n",
       "      <th>Promo_Group</th>\n",
       "      <th>Promo_Period</th>\n",
       "      <th>Promo_Density</th>\n",
       "      <th>Promo_T_boiling</th>\n",
       "      <th>CO_Conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.125073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.498</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.92</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1337.58</td>\n",
       "      <td>11.0</td>\n",
       "      <td>196.966569</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.631431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.368569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.498</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.92</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1337.58</td>\n",
       "      <td>11.0</td>\n",
       "      <td>196.966569</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.396856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.603144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.498</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.92</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1337.58</td>\n",
       "      <td>11.0</td>\n",
       "      <td>196.966569</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.125073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.498</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.92</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1337.58</td>\n",
       "      <td>11.0</td>\n",
       "      <td>196.966569</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.631431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.368569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.498</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.92</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1337.58</td>\n",
       "      <td>11.0</td>\n",
       "      <td>196.966569</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pt        Au   Ru   Rh   Ir   Cu   Pd  IWI  WI  CI  SI  SGP  CP  HDP  UGC  \\\n",
       "0  0.0  0.874927  0.0  0.0  0.0  0.0  0.0    0   0   0   0    0   0    0    0   \n",
       "1  0.0  2.631431  0.0  0.0  0.0  0.0  0.0    0   0   0   0    0   0    0    0   \n",
       "2  0.0  4.396856  0.0  0.0  0.0  0.0  0.0    0   0   0   0    0   0    0    0   \n",
       "3  0.0  0.874927  0.0  0.0  0.0  0.0  0.0    0   0   0   0    0   0    0    0   \n",
       "4  0.0  2.631431  0.0  0.0  0.0  0.0  0.0    0   0   0   0    0   0    0    0   \n",
       "\n",
       "   SCT  FSP  ME  DP  Calc T (oC)  Calc T. (hr)  Al2O3  MgO       CeO2  TiO2  \\\n",
       "0    0    0   0   1           25           0.0    0.0  0.0  99.125073   0.0   \n",
       "1    0    0   0   1           25           0.0    0.0  0.0  97.368569   0.0   \n",
       "2    0    0   0   1           25           0.0    0.0  0.0  95.603144   0.0   \n",
       "3    0    0   0   1           25           0.0    0.0  0.0  99.125073   0.0   \n",
       "4    0    0   0   1           25           0.0    0.0  0.0  97.368569   0.0   \n",
       "\n",
       "   ZEO  MnO  Y2O3  ZrO2  HAP  ACC  Tb4O7  HfO2  La2O3  Co3O4  ThO2  SiO2  \\\n",
       "0  0.0  0.0   0.0   0.0  0.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "1  0.0  0.0   0.0   0.0  0.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "2  0.0  0.0   0.0   0.0  0.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "3  0.0  0.0   0.0   0.0  0.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "4  0.0  0.0   0.0   0.0  0.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "\n",
       "   Fe2O3  Sm2O3  Gd2O3  Yb2O3  CaO  YSZ   Li   Ce   Co   Mg   Fe   Mn   Zr  \\\n",
       "0    0.0    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    0.0    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2    0.0    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3    0.0    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4    0.0    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     K   Ni   Ca   Cs    V   Rb    Y   Na   La   Gd   Yb   Zn   Re   Ti   Cr  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    Ho   Nd   Tm   Sm   Er   Sr  Temperature (C)  H2 vol.%  O2 vol.%  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0            140.0       0.0       0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0            140.0       0.0       0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0            140.0       0.0       0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0            170.0       0.0       0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0            170.0       0.0       0.0   \n",
       "\n",
       "   CO vol.%  H2O vol.%  CO2 vol.%  CH4 vol.%  TOS (min)  F/W (mg.min/ml)  \\\n",
       "0     4.498       30.6        0.0        0.0       60.0              2.0   \n",
       "1     4.498       30.6        0.0        0.0       60.0              2.0   \n",
       "2     4.498       30.6        0.0        0.0       60.0              2.0   \n",
       "3     4.498       30.6        0.0        0.0       60.0              2.0   \n",
       "4     4.498       30.6        0.0        0.0       60.0              2.0   \n",
       "\n",
       "   Metal_Radius_Kittel  Metal_EN_Allen  Metal_Atomic_Num  Metal_T_melt  \\\n",
       "0                 1.44            1.92              79.0       1337.58   \n",
       "1                 1.44            1.92              79.0       1337.58   \n",
       "2                 1.44            1.92              79.0       1337.58   \n",
       "3                 1.44            1.92              79.0       1337.58   \n",
       "4                 1.44            1.92              79.0       1337.58   \n",
       "\n",
       "   Metal_VE_Villars  Metal_Atomic_Wt  Metal_Group  Metal_Period  \\\n",
       "0              11.0       196.966569         11.0           6.0   \n",
       "1              11.0       196.966569         11.0           6.0   \n",
       "2              11.0       196.966569         11.0           6.0   \n",
       "3              11.0       196.966569         11.0           6.0   \n",
       "4              11.0       196.966569         11.0           6.0   \n",
       "\n",
       "   Metal_Density  Metal_T_boiling  Promo_Radius_Kittel  Promo_EN_Allen  \\\n",
       "0         19.282           3129.0                  0.0             0.0   \n",
       "1         19.282           3129.0                  0.0             0.0   \n",
       "2         19.282           3129.0                  0.0             0.0   \n",
       "3         19.282           3129.0                  0.0             0.0   \n",
       "4         19.282           3129.0                  0.0             0.0   \n",
       "\n",
       "   Promo_Atomic_Num  Promo_T_melt  Promo_VE_Villars  Promo_Atomic_Wt  \\\n",
       "0               0.0           0.0               0.0              0.0   \n",
       "1               0.0           0.0               0.0              0.0   \n",
       "2               0.0           0.0               0.0              0.0   \n",
       "3               0.0           0.0               0.0              0.0   \n",
       "4               0.0           0.0               0.0              0.0   \n",
       "\n",
       "   Promo_Group  Promo_Period  Promo_Density  Promo_T_boiling  CO_Conversion  \n",
       "0          0.0           0.0            0.0              0.0            7.6  \n",
       "1          0.0           0.0            0.0              0.0           11.1  \n",
       "2          0.0           0.0            0.0              0.0           18.0  \n",
       "3          0.0           0.0            0.0              0.0           13.2  \n",
       "4          0.0           0.0            0.0              0.0           26.3  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('./project_data/WGS_Catalyst_Data_4316_Mpct_Descriptors.csv')\n",
    "df=df.drop(['Total # of Data'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[''].tolist(), bins=30)\n",
    "plt.xlabel('%')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from math import exp, sqrt\n",
    "import math\n",
    "\n",
    "def _my_power_2(row):\n",
    "    return pow(row[0], 2)         \n",
    "\n",
    "def _my_power_3(row):\n",
    "    return pow(row[0], 3)    \n",
    "\n",
    "def _my_power_m1(row):\n",
    "    return pow(row[0],-1)\n",
    "\n",
    "def _my_power_m2(row):\n",
    "    return pow(row[0],-2)\n",
    "\n",
    "def _my_power_m3(row):\n",
    "    return pow(row[0],-3)\n",
    "\n",
    "def _my_abs_sqrt(row):\n",
    "    return math.sqrtabs(abs(row[0]))\n",
    "    \n",
    "def _my_exp(row):\n",
    "    return exp(row[0])\n",
    "\n",
    "def _my_exp_power_2(row):\n",
    "    return exp(pow(row[0], 2))\n",
    "\n",
    "def _my_exp_power_3(row):\n",
    "    return exp(pow(row[0], 3))\n",
    "\n",
    "def _my_sum(row):\n",
    "    return row[0] + row[1]\n",
    "    \n",
    "def _my_abs_sum(row):\n",
    "    return abs(row[0] + row[1])\n",
    "\n",
    "def _my_abs_diff(row):\n",
    "    return abs(row[0] - row[1])   \n",
    "\n",
    "def _my_diff(row):\n",
    "    return row[0] - row[1] \n",
    "\n",
    "def _my_div(row):\n",
    "    return row[0]/row[1]\n",
    "    \n",
    "def _my_sum_power_2(row):\n",
    "    return pow((row[0] + row[1]), 2)\n",
    "\n",
    "def _my_sum_power_3(row):\n",
    "    return pow((row[0] + row[1]), 3)\n",
    "    \n",
    "def _my_sum_exp(row):\n",
    "    return exp(row[0] + row[1])\n",
    "\n",
    "def _my_sum_exp_power_2(row):\n",
    "    return exp(pow(row[0] + row[1], 2))\n",
    "\n",
    "def _my_sum_exp_power_3(row):\n",
    "    return exp(pow(row[0] + row[1], 3))\n",
    "  \n",
    "def combine_features(df=None, allowed_operations=None, is_print=True):\n",
    "    \"\"\"Generate combination of features given a dataframe and a list of allowed operations.\n",
    "    \n",
    "    For the exponentials, we introduce a characteristic energy/length\n",
    "    converting the \n",
    "    ..todo:: Fix under/overflow errors, and introduce handling of exceptions.\n",
    "\n",
    "    \"\"\"\n",
    "    if is_print:\n",
    "        if allowed_operations:\n",
    "            print('Selected operations:\\n {0}'.format(allowed_operations)) \n",
    "        else:\n",
    "            print('No allowed operations selected.') \n",
    "        \n",
    "    columns_ = df.columns.tolist()    \n",
    "    \n",
    "    #Same units\n",
    "    dict_features = {\n",
    "        'Metal_Density':'a0', \n",
    "        'Metal_T_boiling': 'a0', \n",
    "        'group': 'a0', \n",
    "\n",
    "        'IP': 'a1', \n",
    "        'EA': 'a1', \n",
    "\n",
    "        'E_HOMO': 'a2', \n",
    "        'E_LUMO': 'a2', \n",
    "\n",
    "\n",
    "        'r_s': 'a3',\n",
    "        'r_p': 'a3',\n",
    "        'r_d': 'a3',\n",
    "        'd': 'a3', \n",
    "   \n",
    "        }\n",
    "        \n",
    "    #get df\n",
    "    df_a0 = df[[col for col in columns_ if dict_features.get(col.split('(', 1)[0])=='a0']].astype('float32')    \n",
    "    df_a1 = df[[col for col in columns_ if dict_features.get(col.split('(', 1)[0])=='a1']].astype('float32')    \n",
    "    df_a2 = df[[col for col in columns_ if dict_features.get(col.split('(', 1)[0])=='a2']].astype('float32')    \n",
    "    df_a3 = df[[col for col in columns_ if dict_features.get(col.split('(', 1)[0])=='a3']].astype('float32')\n",
    "    \n",
    "    \n",
    "    #Get column names\n",
    "    col_a0 = df_a0.columns.tolist()\n",
    "    col_a1 = df_a1.columns.tolist()\n",
    "    col_a2 = df_a2.columns.tolist()\n",
    "    col_a3 = df_a3.columns.tolist()\n",
    "   \n",
    "    \n",
    "    #  this list will at the end all the dataframes created\n",
    "    df_list = []\n",
    "\n",
    "    df_b0_list = []    \n",
    "    df_b1_list = []\n",
    "    df_b2_list = []\n",
    "    df_b3_list = []\n",
    "    df_c3_list = []\n",
    "    df_d3_list = []\n",
    "    df_e3_list = []\n",
    "    df_f1_list = []\n",
    "    df_f2_list = []\n",
    "    df_f3_list = []\n",
    "    df_x1_list = []\n",
    "    df_x2_list = []\n",
    "    df_x_list = []\n",
    "\n",
    "\n",
    "    # create b0: absolute differences and sums of a0   \n",
    "    # this is not in the PRL. \n",
    "    \n",
    "    #combine 2 features\n",
    "    for subset in itertools.combinations(col_a0, 2):\n",
    "        if '+' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')']        \n",
    "            data = df_a0[list(subset)].apply(_my_sum, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))         \n",
    "            \n",
    "        if '-' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'-'+subset[1]+')']        \n",
    "            data = df_a0[list(subset)].apply(_my_diff, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))   \n",
    "            \n",
    "            cols = ['('+subset[1]+'-'+subset[0]+')']        \n",
    "            data = df_a0[list(subset)].apply(_my_diff, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))  \n",
    "        \n",
    "        if '|+|' in allowed_operations:\n",
    "            cols = ['|'+subset[0]+'+'+subset[1]+'|']        \n",
    "            data = df_a0[list(subset)].apply(_my_abs_sum, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))     \n",
    "        \n",
    "        if '|-|' in allowed_operations:\n",
    "            cols = ['|'+subset[0]+'-'+subset[1]+'|']        \n",
    "            data = df_a0[list(subset)].apply(_my_abs_diff, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))  \n",
    "            \n",
    "        if '/' in allowed_operations:\n",
    "            cols = [subset[0]+'/'+subset[1]]        \n",
    "            data = df_a0[list(subset)].apply(_my_div, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))  \n",
    "\n",
    "            cols = [subset[1]+'/'+subset[0]]        \n",
    "            data = df_a0[list(subset)].apply(_my_div, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))  \n",
    "\n",
    "    \n",
    "    # one feature\n",
    "    for subset in itertools.combinations(col_a0, 1):\n",
    "        if '^2' in allowed_operations:\n",
    "            cols = [subset[0]+'^2']        \n",
    "            data = df_a0[list(subset)].apply(_my_power_2, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))    \n",
    "            \n",
    "        if '^3' in allowed_operations:\n",
    "            cols = [subset[0]+'^3']   \n",
    "            data = df_a0[list(subset)].apply(_my_power_3, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols)) \n",
    "\n",
    "        if 'exp' in allowed_operations:\n",
    "            cols = ['exp('+subset[0]+')']       \n",
    "            data = df_a0[list(subset)].apply(_my_exp, axis=1)            \n",
    "            df_b0_list.append(pd.DataFrame(data, columns=cols))        \n",
    "        \n",
    "        \n",
    "    # create b1: absolute differences and sums of a1    \n",
    "    for subset in itertools.combinations(col_a1, 2):\n",
    "        if '+' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')']        \n",
    "            data = df_a1[list(subset)].apply(_my_sum, axis=1)            \n",
    "            df_b1_list.append(pd.DataFrame(data, columns=cols))         \n",
    "            \n",
    "        if '-' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'-'+subset[1]+')']        \n",
    "            data = df_a1[list(subset)].apply(_my_diff, axis=1)            \n",
    "            df_b1_list.append(pd.DataFrame(data, columns=cols))   \n",
    "\n",
    "        if '|+|' in allowed_operations:\n",
    "            cols = ['|'+subset[0]+'+'+subset[1]+'|']        \n",
    "            data = df_a1[list(subset)].apply(_my_abs_sum, axis=1)            \n",
    "            df_b1_list.append(pd.DataFrame(data, columns=cols))     \n",
    "            \n",
    "        if '|-|' in allowed_operations:\n",
    "            cols = ['|'+subset[0]+'-'+subset[1]+'|']        \n",
    "            data = df_a1[list(subset)].apply(_my_abs_diff, axis=1)            \n",
    "            df_b1_list.append(pd.DataFrame(data, columns=cols))  \n",
    "\n",
    "    # create b2: absolute differences and sums of a2    \n",
    "    for subset in itertools.combinations(col_a2, 2):\n",
    "        if '+' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')']        \n",
    "            data = df_a2[list(subset)].apply(_my_sum, axis=1)            \n",
    "            df_b2_list.append(pd.DataFrame(data, columns=cols))         \n",
    "            \n",
    "        if '-' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'-'+subset[1]+')']        \n",
    "            data = df_a2[list(subset)].apply(_my_diff, axis=1)            \n",
    "            df_b2_list.append(pd.DataFrame(data, columns=cols))   \n",
    "\n",
    "        if '|+|' in allowed_operations:\n",
    "            cols = ['|'+subset[0]+'+'+subset[1]+'|']        \n",
    "            data = df_a2[list(subset)].apply(_my_abs_sum, axis=1)            \n",
    "            df_b2_list.append(pd.DataFrame(data, columns=cols))         \n",
    "            \n",
    "        if '|-|' in allowed_operations:\n",
    "            cols = ['|'+subset[0]+'-'+subset[1]+'|']        \n",
    "            data = df_a2[list(subset)].apply(_my_abs_diff, axis=1)            \n",
    "            df_b2_list.append(pd.DataFrame(data, columns=cols))   \n",
    " \n",
    "    # create b3: absolute differences and sums of a3    \n",
    "    for subset in itertools.combinations(col_a3, 2):\n",
    "        if '+' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')']        \n",
    "            data = df_a3[list(subset)].apply(_my_sum, axis=1)            \n",
    "            df_b3_list.append(pd.DataFrame(data, columns=cols))         \n",
    "            \n",
    "        if '-' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'-'+subset[1]+')']        \n",
    "            data = df_a3[list(subset)].apply(_my_diff, axis=1)            \n",
    "            df_b3_list.append(pd.DataFrame(data, columns=cols))              \n",
    "\n",
    "        if '|+|' in allowed_operations:\n",
    "            cols = ['|'+subset[0]+'+'+subset[1]+'|']        \n",
    "            data = df_a3[list(subset)].apply(_my_abs_sum, axis=1)            \n",
    "            df_b3_list.append(pd.DataFrame(data, columns=cols))  \n",
    "            \n",
    "        if '|-|' in allowed_operations:\n",
    "            cols = ['|'+subset[0]+'-'+subset[1]+'|']        \n",
    "            data = df_a3[list(subset)].apply(_my_abs_diff, axis=1)            \n",
    "            df_b3_list.append(pd.DataFrame(data, columns=cols))              \n",
    "\n",
    "    # create c3: two steps:\n",
    "    # 1) squares of a3 - unary operations \n",
    "    # we kept itertools.combinations to make the code more uniform with the binary operations\n",
    "    for subset in itertools.combinations(col_a3, 1):\n",
    "        if '^2' in allowed_operations:\n",
    "            cols = [subset[0]+'^2']        \n",
    "            data = df_a3[list(subset)].apply(_my_power_2, axis=1)            \n",
    "            df_c3_list.append(pd.DataFrame(data, columns=cols))    \n",
    "        if '^3' in allowed_operations:\n",
    "            cols = [subset[0]+'^3']   \n",
    "            data = df_a3[list(subset)].apply(_my_power_3, axis=1)            \n",
    "            df_c3_list.append(pd.DataFrame(data, columns=cols)) \n",
    "\n",
    "            \n",
    "    # 2) squares of b3 (only sums) --> sum squared of a3\n",
    "    for subset in itertools.combinations(col_a3, 2):\n",
    "        if '^2' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')^2']   \n",
    "            data = df_a3[list(subset)].apply(_my_sum_power_2, axis=1)            \n",
    "            df_c3_list.append(pd.DataFrame(data, columns=cols))        \n",
    "            \n",
    "        if '^3' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')^3']        \n",
    "            data = df_a3[list(subset)].apply(_my_sum_power_3, axis=1)            \n",
    "            df_c3_list.append(pd.DataFrame(data, columns=cols))\n",
    "\n",
    "    # create d3: two steps:\n",
    "    # 1) exponentials of a3 - unary operations \n",
    "    # we kept itertools.combinations to make the code more uniform with the binary operations\n",
    "    for subset in itertools.combinations(col_a3, 1):\n",
    "        if 'exp' in allowed_operations:\n",
    "            cols = ['exp('+subset[0]+')']      \n",
    "            df_subset = df_a3[list(subset)]\n",
    "            data = df_subset.apply(_my_exp, axis=1)            \n",
    "            df_d3_list.append(pd.DataFrame(data, columns=cols))    \n",
    "            \n",
    "    # 2) exponentials of b3 (only sums) --> exponential of sum of a3\n",
    "    for subset in itertools.combinations(col_a3, 2):\n",
    "        if 'exp' in allowed_operations:\n",
    "            cols = ['exp('+subset[0]+'+'+subset[1]+')']    \n",
    "            df_subset = df_a3[list(subset)]\n",
    "            data = df_subset.apply(_my_sum_exp, axis=1)               \n",
    "            df_d3_list.append(pd.DataFrame(data, columns=cols))        \n",
    "\n",
    "    # create e3: two steps:\n",
    "    # 1) exponentials of squared a3 - unary operations \n",
    "    # we kept itertools.combinations to make the code more uniform with the binary operations\n",
    "    for subset in itertools.combinations(col_a3, 1):\n",
    "        operations={'exp', '^2'}\n",
    "        if operations <= set(allowed_operations):\n",
    "            cols = ['exp('+subset[0]+'^2)']\n",
    "            df_subset = df_a3[list(subset)]\n",
    "            data = df_subset.apply(_my_exp_power_2, axis=1)            \n",
    "            df_e3_list.append(pd.DataFrame(data, columns=cols))    \n",
    "            \n",
    "        operations={'exp', '^3'}\n",
    "        if operations <= set(allowed_operations):\n",
    "            try:\n",
    "                cols = ['exp('+subset[0]+'^3)']\n",
    "                df_subset = df_a3[list(subset)]\n",
    "                data = df_subset.apply(_my_exp_power_3, axis=1)            \n",
    "                df_e3_list.append(pd.DataFrame(data, columns=cols)) \n",
    "            except OverflowError as e:\n",
    "                print('Dropping feature combination that caused under/overflow.\\n')\n",
    "\n",
    "            \n",
    "    # 2) exponentials of b3 (only sums) --> exponential of sum of a3\n",
    "    for subset in itertools.combinations(col_a3, 2):\n",
    "        operations={'exp', '^2'}\n",
    "        if operations <= set(allowed_operations):\n",
    "            cols = ['exp(('+subset[0]+'+'+subset[1]+')^2)']\n",
    "            df_subset = df_a3[list(subset)]\n",
    "            data = df_subset.apply(_my_sum_exp_power_2, axis=1)            \n",
    "            df_e3_list.append(pd.DataFrame(data, columns=cols))        \n",
    "\n",
    "        operations={'exp', '^3'}\n",
    "        if operations <= set(allowed_operations):\n",
    "            try:\n",
    "                cols = ['exp(('+subset[0]+'+'+subset[1]+')^3)']\n",
    "                df_subset = df_a3[list(subset)]\n",
    "                data = df_subset.apply(_my_sum_exp_power_3, axis=1)            \n",
    "                df_e3_list.append(pd.DataFrame(data, columns=cols))   \n",
    "            except OverflowError as e:\n",
    "                print('Dropping feature combination that caused under/overflow.\\n')\n",
    "\n",
    "    # make dataframes from lists, check if they are not empty\n",
    "    # we make there here because they are going to be used to further\n",
    "    # combine the features\n",
    "    if not df_a0.empty: \n",
    "        df_list.append(df_a0)\n",
    "        \n",
    "    if not df_a1.empty: \n",
    "        df_x1_list.append(df_a1)\n",
    "        df_list.append(df_a1)\n",
    "\n",
    "    if not df_a2.empty: \n",
    "        df_x1_list.append(df_a2)\n",
    "        df_list.append(df_a2)\n",
    "        \n",
    "    if not df_a3.empty: \n",
    "        df_x1_list.append(df_a3)\n",
    "        df_list.append(df_a3)\n",
    "\n",
    "\n",
    "\n",
    "    if df_b0_list: \n",
    "        df_b0 = pd.concat(df_b0_list, axis=1)\n",
    "        col_b0 = df_b0.columns.tolist()\n",
    "        #df_b0.to_csv('./df_b0.csv', index=True)\n",
    "        df_list.append(df_b0)\n",
    "        print(\"df_b0\")\n",
    "        print(col_b0)\n",
    "    #X1   \n",
    "    if df_b1_list: \n",
    "        df_b1 = pd.concat(df_b1_list, axis=1)\n",
    "        col_b1 = df_b1.columns.tolist()\n",
    "       #df_x1_list.append(df_b1)\n",
    "        df_list.append(df_b1)\n",
    "        print(\"df_b1\")\n",
    "        print(col_b1)\n",
    "\n",
    "    if df_b2_list: \n",
    "        df_b2 = pd.concat(df_b2_list, axis=1)\n",
    "        col_b2 = df_b2.columns.tolist()\n",
    "        #df_x1_list.append(df_b2) \n",
    "        df_list.append(df_b2)\n",
    "        print(\"df_b2\")\n",
    "        print(col_b2)\n",
    "        \n",
    "    if df_b3_list: \n",
    "        df_b3 = pd.concat(df_b3_list, axis=1)\n",
    "        col_b3 = df_b3.columns.tolist()        \n",
    "        #df_x1_list.append(df_b3) \n",
    "        df_list.append(df_b3)\n",
    "        print(\"df_b3\")\n",
    "        print(col_b3)\n",
    "    #X2\n",
    "    if df_c3_list:\n",
    "        df_c3 = pd.concat(df_c3_list, axis=1)\n",
    "        col_c3 = df_c3.columns.tolist()\n",
    "        #df_x2_list.append(df_c3) \n",
    "        df_list.append(df_c3)\n",
    "        print(\"df_c3\")\n",
    "        print(col_c3)\n",
    "\n",
    "    if df_d3_list:\n",
    "        df_d3 = pd.concat(df_d3_list, axis=1)\n",
    "        col_d3 = df_d3.columns.tolist()\n",
    "        #df_x2_list.append(df_d3) \n",
    "        df_list.append(df_d3)\n",
    "        print(\"df_d3\")\n",
    "        print(col_d3)\n",
    "\n",
    "    if df_e3_list:\n",
    "        df_e3 = pd.concat(df_e3_list, axis=1)\n",
    "        col_e3 = df_e3.columns.tolist()\n",
    "        #df_x2_list.append(df_e3) \n",
    "        df_list.append(df_e3)\n",
    "        print(\"df_e3\")\n",
    "        print(col_e3)\n",
    "    \n",
    "    '''\n",
    "    #combine again\n",
    "    if df_x1_list:\n",
    "        df_x1 = pd.concat(df_x1_list, axis=1)\n",
    "        col_x1 = df_x1.columns.tolist()\n",
    "        print(\"df_x1\")\n",
    "        print(col_x1)\n",
    "                \n",
    "    if df_x2_list:\n",
    "        df_x2 = pd.concat(df_x2_list, axis=1)\n",
    "        col_x2 = df_x2.columns.tolist()\n",
    "        print(\"df_x2\")\n",
    "        print(col_x2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if df_x1_list and df_x2_list:\n",
    "        for el_x1 in col_x1:\n",
    "            for el_x2 in col_x2:\n",
    "                if '/' in allowed_operations:\n",
    "                    cols = [el_x1+'/'+el_x2] \n",
    "                    #now the operation is between two dataframes\n",
    "                    data = df_x1[el_x1].divide(df_x2[el_x2])     \n",
    "                    df_x_list.append(pd.DataFrame(data, columns=cols)) \n",
    "                    print(\"df_x_list\")\n",
    "                    print(df_x_list)\n",
    "\n",
    "                \n",
    "    if df_x_list:\n",
    "        df_x = pd.concat(df_x_list, axis=1)\n",
    "        col_x = df_x.columns.tolist()\n",
    "        df_list.append(df_x)\n",
    "        print(\"df_x\")\n",
    "        print(col_x)\n",
    "    '''\n",
    "\n",
    "    if df_list:\n",
    "        df_combined_features = pd.concat(df_list, axis=1)\n",
    "    elif is_print:\n",
    "        print('No features selected. Please select at least two primary features.')\n",
    "        \n",
    "\n",
    "    if is_print:\n",
    "        print('Number of total features generated: {0}'.format(df_combined_features.shape[1]))\n",
    "    \n",
    "    return df_combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(selected_feature_list, allowed_operations):\n",
    "    # add both '(A)', '(B)' to each feature\n",
    "    selected_featureAB_list = [f+A_or_B for f in selected_feature_list for A_or_B in ['(A)', '(B)']]\n",
    "    \n",
    "    # extract energy differences and selected features from df_data \n",
    "    P = df['CO_Conversion'].values\n",
    "    df_features = df[selected_feature_list]\n",
    "    # derive new features using allowed_operations\n",
    "    df_combined = combine_features(df=df_features, allowed_operations=allowed_operations)\n",
    "    return P,df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected operations:\n",
      " ['+']\n",
      "df_b0\n",
      "['(Metal_Density+Metal_T_boiling)']\n",
      "Number of total features generated: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metal_Density</th>\n",
       "      <th>Metal_T_boiling</th>\n",
       "      <th>(Metal_Density+Metal_T_boiling)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.282</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3148.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>12.370</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4435.370117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4295 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metal_Density  Metal_T_boiling  (Metal_Density+Metal_T_boiling)\n",
       "0            19.282           3129.0                      3148.281982\n",
       "1            19.282           3129.0                      3148.281982\n",
       "2            19.282           3129.0                      3148.281982\n",
       "3            19.282           3129.0                      3148.281982\n",
       "4            19.282           3129.0                      3148.281982\n",
       "5            19.282           3129.0                      3148.281982\n",
       "6            19.282           3129.0                      3148.281982\n",
       "7            19.282           3129.0                      3148.281982\n",
       "8            19.282           3129.0                      3148.281982\n",
       "9            19.282           3129.0                      3148.281982\n",
       "10           19.282           3129.0                      3148.281982\n",
       "11           19.282           3129.0                      3148.281982\n",
       "12           19.282           3129.0                      3148.281982\n",
       "13           19.282           3129.0                      3148.281982\n",
       "14           19.282           3129.0                      3148.281982\n",
       "15           19.282           3129.0                      3148.281982\n",
       "16           19.282           3129.0                      3148.281982\n",
       "17           19.282           3129.0                      3148.281982\n",
       "18           19.282           3129.0                      3148.281982\n",
       "19           19.282           3129.0                      3148.281982\n",
       "20           19.282           3129.0                      3148.281982\n",
       "21           19.282           3129.0                      3148.281982\n",
       "22           19.282           3129.0                      3148.281982\n",
       "23           19.282           3129.0                      3148.281982\n",
       "24           19.282           3129.0                      3148.281982\n",
       "25           19.282           3129.0                      3148.281982\n",
       "26           19.282           3129.0                      3148.281982\n",
       "27           19.282           3129.0                      3148.281982\n",
       "28           19.282           3129.0                      3148.281982\n",
       "29           19.282           3129.0                      3148.281982\n",
       "...             ...              ...                              ...\n",
       "4265         12.370           4423.0                      4435.370117\n",
       "4266         12.370           4423.0                      4435.370117\n",
       "4267         12.370           4423.0                      4435.370117\n",
       "4268         12.370           4423.0                      4435.370117\n",
       "4269         12.370           4423.0                      4435.370117\n",
       "4270         12.370           4423.0                      4435.370117\n",
       "4271         12.370           4423.0                      4435.370117\n",
       "4272         12.370           4423.0                      4435.370117\n",
       "4273         12.370           4423.0                      4435.370117\n",
       "4274         12.370           4423.0                      4435.370117\n",
       "4275         12.370           4423.0                      4435.370117\n",
       "4276         12.370           4423.0                      4435.370117\n",
       "4277         12.370           4423.0                      4435.370117\n",
       "4278         12.370           4423.0                      4435.370117\n",
       "4279         12.370           4423.0                      4435.370117\n",
       "4280         12.370           4423.0                      4435.370117\n",
       "4281         12.370           4423.0                      4435.370117\n",
       "4282         12.370           4423.0                      4435.370117\n",
       "4283         12.370           4423.0                      4435.370117\n",
       "4284         12.370           4423.0                      4435.370117\n",
       "4285         12.370           4423.0                      4435.370117\n",
       "4286         12.370           4423.0                      4435.370117\n",
       "4287         12.370           4423.0                      4435.370117\n",
       "4288         12.370           4423.0                      4435.370117\n",
       "4289         12.370           4423.0                      4435.370117\n",
       "4290         12.370           4423.0                      4435.370117\n",
       "4291         12.370           4423.0                      4435.370117\n",
       "4292         12.370           4423.0                      4435.370117\n",
       "4293         12.370           4423.0                      4435.370117\n",
       "4294         12.370           4423.0                      4435.370117\n",
       "\n",
       "[4295 rows x 3 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selected_feature_list = ['IP', 'EA', 'E_HOMO', 'E_LUMO', 'r_s', 'r_p', 'r_d', 'Z', 'period']\n",
    "'''\n",
    "'period':'a0', 'Z': 'a0', 'group': 'a0', \n",
    "\n",
    "'IP': 'a1', 'EA': 'a1', \n",
    "\n",
    "'E_HOMO': 'a2', 'E_LUMO': 'a2', \n",
    "\n",
    "'r_s': 'a3', 'r_p': 'a3', 'r_d': 'a3', 'd': 'a3', \n",
    "   \n",
    "'''\n",
    "selected_feature_list =  ['Metal_Density', 'Metal_T_boiling']\n",
    "\n",
    "# allowed_operations = ['+', '-', '|-|', '/' '^2', '^3',  'exp']\n",
    "allowed_operations = ['+']\n",
    "\n",
    "P,df_D = get_data(selected_feature_list, allowed_operations)\n",
    "\n",
    "# print derived features\n",
    "df_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining low-dimensional descriptors with the $\\ell_0$ method\n",
    "\n",
    "<div style=\"list-style:disc; margin: 2px;padding: 10px;border: 0px;border:8px double   green; font-size:16px;padding-left: 32px;padding-right: 22px; width:89%\">\n",
    "<li> Perform an $\\ell_0$-regularization to identify the best low dimensional descriptors using the primary features.</li>\n",
    "<li> Show that non-linear functions of the primary features improve the models significantly. </li>\n",
    "<li> See that the $\\ell_0$-regularization can rapidly become computational infeasible.</li>\n",
    "</div>\n",
    "\n",
    "Our target is to find the best low dimensional descriptor for a linear model $\\mathbf{P} = \\mathbf{D^\\ast}\\mathbf{c^\\ast}$, where $\\mathbf{c^\\ast}$ is the vector of nonzero elements of the solution vector $\\mathbf{c}$ and $\\mathbf{D^\\ast}$ is the matrix of the columns of $\\mathbf{D}$ corresponding to the nonzero elements of $\\mathbf{c}$. The $\\ell_0$ regularization\n",
    "\n",
    "$\\text{argmin}_{\\mathbf{c} \\in \\mathbb{R}^{m}} \\{\\|\\mathbf{P} - \\mathbf{D}\\mathbf{c}\\|^2_2 +\\lambda \\|\\mathbf{c}\\|_0\\}$\n",
    "\n",
    "provides exactly what we want. It is defined in the following and solved combinatorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L0(P, D, dimension):\n",
    "    n_rows, n_columns = D.shape\n",
    "    D = np.column_stack((D, np.ones(n_rows)))\n",
    "    SE_min = np.inner(P ,P)\n",
    "    coef_min, permu_min = None, None\n",
    "    for permu in combinations(range(n_columns), dimension):\n",
    "        D_ls = D[:, permu + (-1,)]\n",
    "        coef, SE, __1, __2 = np.linalg.lstsq(D_ls, P, rcond=-1)\n",
    "        try:\n",
    "            if SE[0] < SE_min: \n",
    "                SE_min = SE[0]\n",
    "                coef_min, permu_min = coef, permu\n",
    "        except:\n",
    "            pass\n",
    "    RMSE = np.sqrt(SE_min/n_rows)\n",
    "    return RMSE, coef_min, permu_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the $\\ell_0$-regularization for different dimensions (numbers of non-zero coefficients in the model) and see the root mean square errors (RMSE) and the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected operations:\n",
      " ['+']\n",
      "df_b0\n",
      "['(Metal_Density+Metal_T_boiling)']\n",
      "Number of total features generated: 3\n",
      "     RMSE   Best desriptor\n",
      " 1D: 32.37475 ['Metal_T_boiling']\n",
      " 2D: 32.35104 ['Metal_T_boiling', '(Metal_Density+Metal_T_boiling)']\n",
      " 3D: 32.27830 ['Metal_Density', 'Metal_T_boiling', '(Metal_Density+Metal_T_boiling)']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-1b17c7ee3a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mRMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%2sD: %.5f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "selected_feature_list = ['Metal_Density', 'Metal_T_boiling']\n",
    "allowed_operations = ['+']\n",
    "\n",
    "P, df_D = get_data(selected_feature_list, allowed_operations)\n",
    "features_list = df_D.columns.tolist()\n",
    "D = df_D.values\n",
    "\n",
    "print(\"     RMSE   Best desriptor\")\n",
    "for dim in range(1,11):\n",
    "    RMSE, coefficients, selected_indices = L0(P,D,dim)\n",
    "    print('%2sD: %.5f' % (dim, RMSE), [features_list[i] for i in selected_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of performing the $\\ell_0$-regularization shows that the accuracy converges fast, e.g. we could leave out some components in the linear model without descreasing the accuracy. The second observation is that a linear model of the atomic features is not enough to describe the RS-ZB energy differences. A way out could be using non-linear machine learning models, e.g. kernel ridge regression or a neural network, instead of linear regression. Another way is to put the non-linearity into the descriptors by building algebraic combinations of the atomic features and mapping the few best of these more complex features onto the target again with a linear model. \n",
    "\n",
    "Run the following script to build larger feature spaces of more complex features and select the best 1D, 2D and 3D desriptor for a linear model using $\\ell_0$-regularization. Plot the results afterwards. How does the accuracy of the models change? How does the feature space size and the dimension of the descriptors depend on the needed time to solve the $\\ell_0$-problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_feature_list = ['r_s', 'r_p', 'r_d', 'EA', 'IP']\n",
    "op_lists = [[], ['+','|-|'], ['+','|-|','exp'], ['+','|-|','exp', '^2'] ]\n",
    "X  = []\n",
    "Errors, Time = np.empty([3,len(op_lists)]), np.empty([3,len(op_lists)])\n",
    "\n",
    "for n_op, allowed_operations in enumerate(op_lists):\n",
    "    P, df_D = get_data(selected_feature_list, allowed_operations)\n",
    "    features_list = df_D.columns.tolist()\n",
    "    D = df_D.values\n",
    "    \n",
    "    number_of_features = len(features_list)\n",
    "    X.append(number_of_features)\n",
    "    for dim in range(1,4):\n",
    "        t1= time()\n",
    "        RMSE, coefficients, selected_indices = L0(P,D,dim)\n",
    "        t2 = time()-t1             \n",
    "        \n",
    "        Time [dim-1][n_op] = t2\n",
    "        Errors[dim-1][n_op] = RMSE \n",
    "        \n",
    "        print(\"n_features: %s; %sD  RMSE: %.3f  best features: %s\" \n",
    "              %(len(features_list), dim, RMSE, [features_list[i] for i in selected_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "f, (ax1, ax2) = plt.subplots(1,2, sharex=True, figsize=(12,8))\n",
    "ax1.set_xlabel('Feature space size')\n",
    "ax2.set_xlabel('Feature space size')\n",
    "ax1.set_ylabel('RMSE [eV/atom]')\n",
    "ax2.set_ylabel('Time [s]')\n",
    "#ax2.set_yscale('log')\n",
    "\n",
    "for dim in range(1,4):\n",
    "    ax1.plot(X, Errors[dim-1], 's-', label='%sD' %dim)\n",
    "    ax2.plot(X, Time[dim-1], 's-', label='%sD' %dim)\n",
    "ax2.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume now that we would like to include thousands or millions of (more) complex features to obtain more accurate models..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximations to the $\\ell_0$ method\n",
    "<div style=\"list-style:disc; margin: 2px;padding: 10px;border: 0px;border:8px double   green; font-size:16px;padding-left: 32px;padding-right: 22px; width:89%\">\n",
    "<li >Perform a LASSO minimization and the SISSO method.</li>\n",
    "<li >Compare the solutions with the ones from the $\\ell_0$ method.</li>\n",
    "</div>\n",
    "\n",
    "### The LASSO\n",
    "\n",
    "\n",
    "One state-of-the art approximation to the $\\ell_0$ method is the LASSO: \n",
    "\n",
    "$\\text{argmin}_{\\mathbf{c} \\in \\mathbb{R}^{m}} \\{\\|\\mathbf{P} - \\mathbf{D}\\mathbf{c}\\|^2_2 +\\lambda \\|\\mathbf{c}\\|_1\\}$.\n",
    "\n",
    "Before performing the LASSO regression we standardize the data to have mean 0 and variance 1, since otherwise the $\\ell_2$-norm of a column would affect bias its contribution to the model. <br>\n",
    "Note that we can use the LASSO also only for feature selection. We use then a least-square model with the selected features afterwards instead of the LASSO model directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_fit(lam, P, D, feature_list):\n",
    "    #LASSO\n",
    "    D_standardized = ss.zscore(D)\n",
    "    lasso =  Lasso(alpha=lam)\n",
    "    lasso.fit(D_standardized, P)\n",
    "    coef =  lasso.coef_\n",
    "    \n",
    "    # get strings of selected features\n",
    "    selected_indices = coef.nonzero()[0]\n",
    "    selected_features = [feature_list[i] for i in selected_indices]\n",
    "    \n",
    "    # get RMSE of LASSO model\n",
    "    P_predict = lasso.predict(D_standardized)\n",
    "    RMSE_LASSO = np.linalg.norm(P-P_predict) / np.sqrt(82.)\n",
    "\n",
    "    #get RMSE for least-square fit\n",
    "    D_new = D[:, selected_indices]\n",
    "    D_new = np.column_stack((D_new, np.ones(82)))\n",
    "    RMSE_LS = np.sqrt(np.linalg.lstsq(D_new, P, rcond=-1)[1][0]/82.)\n",
    "        \n",
    "    return RMSE_LASSO, RMSE_LS, coef, selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ regulates the sparsity of the coefficient vector of the model. Get the data and try different $\\lambda$ by adjusting the varibale lam. How good does LASSO (directly or with a least-square fit afterwards) approximate the L0-method (when the same feature space is used for both)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import Data\n",
    "selected_feature_list = ['r_s', 'r_p', 'r_d', 'EA', 'IP']\n",
    "allowed_operations = ['+','|-|','exp', '^2']\n",
    "P, df_D = get_data(selected_feature_list, allowed_operations)\n",
    "D = df_D.values\n",
    "features_list = df_D.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change lam between 0.02 and 0.34, e.g. 0.34, 0.30, 0.20, 0.13, 0.10, 0.02\n",
    "lam = 0.2\n",
    "\n",
    "RMSE_LASSO, RMSE_LS, coef, selected_features = lasso_fit(lam, P, D, features_list)\n",
    "plt.bar(range(len(coef)), np.abs(coef))\n",
    "plt.xlabel(\"Coefficient index $i$\")\n",
    "plt.ylabel(\"$|c_i|$\")\n",
    "\n",
    "print(\"lambda: %.3f\\t dimension of descriptor: %s\\t RMSE_LASSO: %.3f\\t RMSE_LS: %.3f\" \n",
    "      %(lam, len(selected_features), RMSE_LASSO, RMSE_LS))\n",
    "print(pd.DataFrame({'features':np.array(selected_features), 'abs(nonzero_coefs_LASSO)': np.abs(coef[coef.nonzero()])}))\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint:\n",
    "Compare these results to the L0 results you have obtained before from the same feature space, copied and pasted in here:<br>\n",
    "\"Number of total features generated: 115 <br>\n",
    "features: 115; 1D  RMSE: 0.296667841349  best features: ['(r_p(A)+r_d(B))'] <br>\n",
    "features: 115; 2D  RMSE: 0.194137970112  best features: ['(r_s(B)+r_p(A))', '(r_s(B)+r_p(A))^2'] <br>\n",
    "features: 115; 3D  RMSE: 0.170545592998  best features: ['(r_s(B)+r_p(A))', '(r_s(B)+r_p(A))^2', 'exp(r_s(B)+r_p(A))']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SISSO method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Data\n",
    "selected_feature_list = ['r_s', 'r_p', 'r_d', 'EA', 'IP']\n",
    "allowed_operations = ['+','|-|','exp', '^2']\n",
    "P, df_D = get_data(selected_feature_list, allowed_operations)\n",
    "D = df_D.values\n",
    "features_list = df_D.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the SISSO algorithm. How does the SISSO method compare to the LASSO and to the $\\ell_0$-regularization in terms of accuracy (again when using the same feature space)? How fast is SISSO compared to the $\\ell_0$-regularization? How does n_features_per_sis_iter (the number of features collected per sis iteration) affect the performance? Note, that for n_features_per_sis_iter=1 SISSO becomes the so-called orthogonal matching pursuit, another well-known compressed sensing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sisso = SissoRegressor(n_nonzero_coefs=3, n_features_per_sis_iter=10)\n",
    "\n",
    "sisso.fit(D, P)\n",
    "sisso.print_models(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the SISSO method with a (relatively) big feature space\n",
    "<div style=\"list-style:disc; margin: 2px;padding: 10px;border: 0px;border:8px double   green; font-size:16px;padding-left: 32px;padding-right: 22px; width:89%\">\n",
    "<li>Reproduce the results from the <a href=\"http://journals.aps.org/prl/abstract/10.1103/PhysRevLett.114.105503\" target=\"_blank\">reference publication</a>  by including further features.</li>\n",
    "<li>Visualize the 2D descriptors in a structure map.</li>\n",
    "<li>Experiment with different settings and investigate the influence of the input parameters on the results. (OPTIONAL)</li>\n",
    "</div>\n",
    "Note the size of the feature space, the needed time to run the code and the accuracy (using the default settings)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for feature space construction\n",
    "selected_feature_list = ['IP', 'EA', 'r_s', 'r_p','r_d']\n",
    "allowed_operations = ['+','|-|','exp','^2', '/']\n",
    "\n",
    "# get the data\n",
    "P, df_D = get_data(selected_feature_list, allowed_operations)\n",
    "D = df_D.values\n",
    "features_list = df_D.columns.tolist()\n",
    "\n",
    "sisso = SissoRegressor(n_nonzero_coefs=3, n_features_per_sis_iter=26)\n",
    "\n",
    "sisso.fit(D, P)\n",
    "sisso.print_models(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, plot an interactive 2D structure map using the 2D descriptor. By <i>hovering</i> over a point in the plot, information regarding that system is displayed. By <i>clicking</i> a point, an interactive 3D visualization of the structure will be displayed below.\n",
    "\n",
    "The markers represent the compounds and their colors the reference energy differences. How well does the descriptor separate the compounds with respect to their crystal structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 2d solution\n",
    "P_predict = sisso.predict(D, dim=2)\n",
    "D_selcted = df_D.values[:, sisso.l0_selected_indices[1]]\n",
    "features = df_D.columns[sisso.l0_selected_indices[1]]\n",
    "\n",
    "# plot 2D map \n",
    "show_map(df, D_selcted, P_predict, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting new materials (extrapolation)\n",
    "<div style=\"list-style:disc; margin: 2px;padding: 10px;border: 0px;border:8px double   green; font-size:16px;padding-left: 32px;padding-right: 22px; width:89%\">\n",
    "<li>Perform a leave-one-out cross-validation (LOOCV) using SISSO.</li>\n",
    "<li>Analyze the prediction accuracy and how often the same descriptor is selected.</li>\n",
    "</div>\n",
    "\n",
    "We have seen that we can fit the energy differences of materials accurately. But what about predicting the energy difference of a 'new' material (which was not included when determining the model)? We test the prediction performance via LOOCV.  In a LOOCV for each material the following procedure is performed: the selected material is excluded, the model is built on the remaining materials and the model accurcy is tested on the excluded material. This means that we need to run SISSO function 82 times. <br>\n",
    "Get the data in the next cell and run the LOOCV  one cell after. Note that running the LOOCV  could take up to ten minutes. Use the remaining two cells of this chapter to analyse the results.<br>\n",
    "How is the prediction error compared to the fitting error? How often is the same descriptor selected? Are there materials that yield an outlying high/low error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "selected_feature_list = ['IP', 'EA', 'r_s', 'r_p','r_d']\n",
    "allowed_operations = ['+','|-|','exp', '^2', '/']\n",
    "\n",
    "P, df_D = get_data(selected_feature_list, allowed_operations)\n",
    "features_list = df_D.columns.tolist()\n",
    "chemical_formulas = df_D.index.tolist()\n",
    "D = df_D.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leave-one-out cross-validation\n",
    "n_compounds = len(P)\n",
    "dimensions = range(1, 4)\n",
    "features_count = [[] for i in range(3)]\n",
    "P_predict = np.empty([len(dimensions), n_compounds])\n",
    "\n",
    "sisso = SissoRegressor(n_nonzero_coefs=3, n_features_per_sis_iter=10)\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "for indices_train, index_test in loo.split(P):\n",
    "    i_cv = index_test[0]\n",
    "    print('%2s) Leave out %s: Ediff_ref = %.3f eV/atom' \n",
    "          % (index_test[0]+1, chemical_formulas[i_cv], P[i_cv]))\n",
    "        \n",
    "    sisso.fit(D[indices_train], P[indices_train])\n",
    "    sisso.print_models(features_list)    \n",
    "    \n",
    "    for dim in dimensions:      \n",
    "        features = [features_list[i] for i in sisso.l0_selected_indices[dim - 1]]\n",
    "        predicted_value = sisso.predict(D[index_test], dim=dim)[0]\n",
    "        \n",
    "        features_count[dim-1].append( tuple(features) )        \n",
    "        P_predict[dim-1, i_cv] = predicted_value\n",
    "        \n",
    "        print('Ediff_predicted(%sD) = %.3f eV/atom' %(dim, predicted_value))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Prediction errors\n",
    "prediction_errors = np.linalg.norm(P-P_predict, axis=1)/np.sqrt(n_compounds)\n",
    "xs = [P] *3\n",
    "ys = P_predict\n",
    "legend = ['%sD, RMSE = %.3f eV/atom' %(dim, prediction_errors[dim-1]) for dim in dimensions]\n",
    "data_point_labels = [df.index.tolist()]*3\n",
    "\n",
    "show_scatter_plot(xs, ys, data_point_labels=data_point_labels, \n",
    "                  x_label='E_diff_DFT', y_label='E_diff_predicted', legend=legend, unit='eV/atom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print descriptor selection frequency\n",
    "print(\"Descriptor selection frequency\")\n",
    "for dim in dimensions:    \n",
    "    df_frequency = pd.DataFrame( Counter(features_count[dim-1]).most_common(10), columns=['Features', 'Frequency'] )\n",
    "    print('-----------------\\n%sD:\\n%s' % (dim, df_frequency))\n",
    "\n",
    "# create table to display errors and models\n",
    "feat = np.array(features_count).flatten('F')\n",
    "Pred = np.array(P_predict).flatten('F')\n",
    "Pred_errors = np.abs(P-P_predict).flatten('F')\n",
    "Ref_values = [r for p in P for r in [p,p,p] ]\n",
    "Mats = [m for mat in chemical_formulas for m in [mat, mat, mat] ]\n",
    "Dims = ['1D','2D','3D'] * n_compounds\n",
    "\n",
    "df_loo = pd.DataFrame(zip(Ref_values,Pred,Pred_errors,feat), index = [Mats,Dims],\n",
    "                  columns=['P_ref[eV]', 'P_pred[eV]', 'abs. error [eV]', 'Selected features'])\n",
    "\n",
    "#  if you do not want to sort the data frame by the prediction error comment out the nex line \n",
    "df_loo = df_loo.sort_values('abs. error [eV]', ascending=False)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "display(df_loo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel ridge regession\n",
    "It is instructive to compare the performance of the just identified model with a model trained with the popular kernel ridge regression (KRR) approach, by using the same list of atomic features as input. \n",
    "KRR solves a $\\ell_2$ regularized linear regression problem, with (typically) a nonlinear kernel.\n",
    "This can be descirbed in the following manner. The $\\ell_2$ regularized linear regression problem is:\n",
    "\n",
    "$\\text{argmin}_{\\mathbf{c} \\in \\mathbb{R}^{m}} \\{\\|\\mathbf{P} - \\mathbf{D}\\mathbf{c}\\|^2_2 +\\lambda \\|\\mathbf{c}\\|_2\\}$.\n",
    "\n",
    "Its solution is:\n",
    "\n",
    "$\\mathbf{c} = \\left( \\mathbf{D}^\\top \\mathbf{D} + \\lambda \\mathbf{I} \\right)^{-1} \\mathbf{D}^\\top \\mathbf{P}$\n",
    "\n",
    "Acoording to Hilbert space representaiton theorem, we can write the solution vector $\\mathbf{c}$ as a linear expansion over the data points represented acoording to the chosen descriptor. In other words, $\\mathbf{c}$ can be represented as a linear expansion over the rows $\\mathbf{d}_j$ of the matrix $\\mathbf{D}$.\n",
    "\n",
    "$\\mathbf{c} = \\sum_j \\alpha_j \\mathbf{d}_j $\n",
    "\n",
    "This rewriting leads to the equivalent problem:\n",
    "\n",
    "$\\text{argmin}_{\\boldsymbol{\\alpha} \\in \\mathbb{R}^{N}} \\{\\|\\mathbf{P} - \\mathbf{K}\\boldsymbol{\\alpha}\\|^2_2 +\\lambda \\boldsymbol{\\alpha}^\\top \\mathbf{K} \\boldsymbol{\\alpha} \\} \\quad (1)$,\n",
    "\n",
    "where the kernel $\\mathbf{K}$ is: $K_{ij} = < \\mathbf{d}_i, \\mathbf{d}_j > $.\n",
    "\n",
    "The rewritten problem has solution $\\boldsymbol{\\alpha} = \\left( \\mathbf{K} + \\lambda \\mathbf{I} \\right)^{-1} \\mathbf{P} \\quad (2)$\n",
    "\n",
    "This rewriting did not add anything to the regularized linear regression approoach. If, however, we now expand the vector $\\mathbf{c}$ as an expansion of nonlinear functions $\\Phi()$ of the vectors $\\mathbf{d}_j: \n",
    "\n",
    "$\\mathbf{c} = \\sum_j \\alpha_j \\Phi(\\mathbf{d}_j) $\n",
    "\n",
    "and the kernel as: $K_{ij} = < \\Phi(\\mathbf{d}_i), \\Phi(\\mathbf{d}_j)> $, one can prove that the same problem (1) with the same solution (2) holds. Normally, people do not specify the function $\\Phi()$, but rahter the kernel.\n",
    "Actually, $\\Phi()$ does not need to be known at all. We refer to the specialized literature on KRR for more details on this method.\n",
    "\n",
    "Here, we make use of the Gaussian kernel, i.e., the most popular one:\n",
    "\n",
    "$K(x, y) = \\exp(-\\gamma ||x-y||^2)$.\n",
    "\n",
    "The parameters $\\lambda$ and $\\gamma$ are called <i> hyperparameters </i> and are set via CV. \n",
    "Specifically, at each LOOCV step, the hyperparameters ($\\ell_2$-regularization parameter $\\lambda$ and inverse gaussian width $\\gamma$) are optimized via a grid search and a so-called 5-fold cross-validation on the training set. This means splitting the training set in 5 subsets, 1 subset is used for evaluating the performance (RMSE) and the other 4 for training. The procedure is repeated 5 times by changing the test subset and the overall perfrmance is the RMSE over all repetitions. \n",
    "\n",
    "What can one observe by comparing the SISSO and KRR results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_list = ['IP', 'EA', 'r_s', 'r_p','r_d']\n",
    "allowed_operations = []\n",
    "\n",
    "P, df_D = get_data(selected_feature_list, allowed_operations)\n",
    "features_list = df_D.columns.tolist()\n",
    "D = df_D.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kr = GridSearchCV(KernelRidge(kernel='rbf'), cv=5,\n",
    "                  param_grid={\"alpha\": np.logspace(-3, 0, 5),\n",
    "                              \"gamma\": np.logspace(-2, 1, 5)})\n",
    "P_predict_kr = []\n",
    "loo = LeaveOneOut()\n",
    "for indices_train, index_test in loo.split(P):\n",
    "    kr.fit(D[indices_train], P[indices_train])\n",
    "    print(\"%2i Ediff_ref: %.3f, Ediff_pred: %.3f, hyperparameters: {'lambda': %.3f, 'gamma':%.3f}\" \n",
    "          % (index_test[0], P[index_test], kr.predict(D[index_test]), \n",
    "          kr.best_params_['alpha'], kr.best_params_['gamma']))\n",
    "    P_predict_kr.append(kr.predict(D[index_test])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rmse_kr = np.linalg.norm(np.array(P_predict_kr) - P)/np.sqrt(P.size)\n",
    "\n",
    "xs = [P, P]\n",
    "ys = [P_predict[-1], P_predict_kr,]\n",
    "legend = ['SISSO 3D, RMSE = %.3f eV/atom' % prediction_errors[dim-1], \n",
    "          'KR, RMSE = %.3f eV/atom' % prediction_rmse_kr]\n",
    "data_point_labels = [df.index.tolist()]*2\n",
    "\n",
    "show_scatter_plot(xs, ys, data_point_labels=data_point_labels, \n",
    "                  x_label='E_diff_DFT', y_label='E_diff_predicted', legend=legend, unit='eV/atom')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
